{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import logging\n",
    "from typing import List\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewsArticle:\n",
    "    def __init__(self, title: str, content: str, date: str, source: str, url: str):\n",
    "        self.title = title\n",
    "        self.content = content\n",
    "        self.date = date\n",
    "        self.source = source\n",
    "        self.url = url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\OM\\AppData\\Roaming\\Python\\Python311\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\OM\\AppData\\Roaming\\Python\\Python311\\site-packages\\huggingface_hub\\file_download.py:651: UserWarning: Not enough free disk space to download the file. The expected file size is: 439.10 MB. The target location C:\\Users\\OM\\.cache\\huggingface\\hub\\models--yiyanghkust--finbert-tone\\blobs only has 291.23 MB free disk space.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "414dc71078d6480194ef2d9b9265cdee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/439M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\OM\\AppData\\Roaming\\Python\\Python311\\site-packages\\huggingface_hub\\file_download.py:651: UserWarning: Not enough free disk space to download the file. The expected file size is: 439.30 MB. The target location C:\\Users\\OM\\.cache\\huggingface\\hub\\models--yiyanghkust--finbert-tone\\blobs only has 0.00 MB free disk space.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c1d156a2eea4e0a98edd5b7ef465750",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tf_model.h5:   0%|          | 0.00/439M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\OM\\AppData\\Roaming\\Python\\Python311\\site-packages\\huggingface_hub\\file_download.py:651: UserWarning: Not enough free disk space to download the file. The expected file size is: 439.10 MB. The target location C:\\Users\\OM\\.cache\\huggingface\\hub\\models--yiyanghkust--finbert-tone\\blobs only has 0.00 MB free disk space.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "734d61cba143455dbdd4c847378bb9de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:  72%|#######1  | 315M/439M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b74b4d846e6450bb3b3176ab283a313",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tf_model.h5:   0%|          | 0.00/439M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Could not load model yiyanghkust/finbert-tone with any of the following classes: (<class 'transformers.models.auto.modeling_auto.AutoModelForSequenceClassification'>, <class 'transformers.models.auto.modeling_tf_auto.TFAutoModelForSequenceClassification'>, <class 'transformers.models.bert.modeling_bert.BertForSequenceClassification'>, <class 'transformers.models.bert.modeling_tf_bert.TFBertForSequenceClassification'>). See the original errors:\n\nwhile loading with AutoModelForSequenceClassification, an error is thrown:\nTraceback (most recent call last):\n  File \"C:\\Users\\OM\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\pipelines\\base.py\", line 289, in infer_framework_load_model\n    model = model_class.from_pretrained(model, **kwargs)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\OM\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\models\\auto\\auto_factory.py\", line 564, in from_pretrained\n    return model_class.from_pretrained(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\OM\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\modeling_utils.py\", line 3805, in from_pretrained\n    resolved_archive_file = cached_file(\n                            ^^^^^^^^^^^^\n  File \"C:\\Users\\OM\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\utils\\hub.py\", line 403, in cached_file\n    resolved_file = hf_hub_download(\n                    ^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\OM\\AppData\\Roaming\\Python\\Python311\\site-packages\\huggingface_hub\\utils\\_validators.py\", line 114, in _inner_fn\n    return fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\OM\\AppData\\Roaming\\Python\\Python311\\site-packages\\huggingface_hub\\file_download.py\", line 860, in hf_hub_download\n    return _hf_hub_download_to_cache_dir(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\OM\\AppData\\Roaming\\Python\\Python311\\site-packages\\huggingface_hub\\file_download.py\", line 1009, in _hf_hub_download_to_cache_dir\n    _download_to_tmp_and_move(\n  File \"C:\\Users\\OM\\AppData\\Roaming\\Python\\Python311\\site-packages\\huggingface_hub\\file_download.py\", line 1543, in _download_to_tmp_and_move\n    http_get(\n  File \"C:\\Users\\OM\\AppData\\Roaming\\Python\\Python311\\site-packages\\huggingface_hub\\file_download.py\", line 455, in http_get\n    temp_file.write(chunk)\nOSError: [Errno 28] No space left on device\n\nwhile loading with TFAutoModelForSequenceClassification, an error is thrown:\nTraceback (most recent call last):\n  File \"C:\\Users\\OM\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\pipelines\\base.py\", line 289, in infer_framework_load_model\n    model = model_class.from_pretrained(model, **kwargs)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\OM\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\models\\auto\\auto_factory.py\", line 564, in from_pretrained\n    return model_class.from_pretrained(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\OM\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\modeling_tf_utils.py\", line 2843, in from_pretrained\n    resolved_archive_file = cached_file(\n                            ^^^^^^^^^^^^\n  File \"C:\\Users\\OM\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\utils\\hub.py\", line 403, in cached_file\n    resolved_file = hf_hub_download(\n                    ^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\OM\\AppData\\Roaming\\Python\\Python311\\site-packages\\huggingface_hub\\utils\\_validators.py\", line 114, in _inner_fn\n    return fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\OM\\AppData\\Roaming\\Python\\Python311\\site-packages\\huggingface_hub\\file_download.py\", line 860, in hf_hub_download\n    return _hf_hub_download_to_cache_dir(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\OM\\AppData\\Roaming\\Python\\Python311\\site-packages\\huggingface_hub\\file_download.py\", line 1009, in _hf_hub_download_to_cache_dir\n    _download_to_tmp_and_move(\n  File \"C:\\Users\\OM\\AppData\\Roaming\\Python\\Python311\\site-packages\\huggingface_hub\\file_download.py\", line 1543, in _download_to_tmp_and_move\n    http_get(\n  File \"C:\\Users\\OM\\AppData\\Roaming\\Python\\Python311\\site-packages\\huggingface_hub\\file_download.py\", line 455, in http_get\n    temp_file.write(chunk)\nOSError: [Errno 28] No space left on device\n\nwhile loading with BertForSequenceClassification, an error is thrown:\nTraceback (most recent call last):\n  File \"C:\\Users\\OM\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\pipelines\\base.py\", line 289, in infer_framework_load_model\n    model = model_class.from_pretrained(model, **kwargs)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\OM\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\modeling_utils.py\", line 3805, in from_pretrained\n    resolved_archive_file = cached_file(\n                            ^^^^^^^^^^^^\n  File \"C:\\Users\\OM\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\utils\\hub.py\", line 403, in cached_file\n    resolved_file = hf_hub_download(\n                    ^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\OM\\AppData\\Roaming\\Python\\Python311\\site-packages\\huggingface_hub\\utils\\_validators.py\", line 114, in _inner_fn\n    return fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\OM\\AppData\\Roaming\\Python\\Python311\\site-packages\\huggingface_hub\\file_download.py\", line 860, in hf_hub_download\n    return _hf_hub_download_to_cache_dir(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\OM\\AppData\\Roaming\\Python\\Python311\\site-packages\\huggingface_hub\\file_download.py\", line 1009, in _hf_hub_download_to_cache_dir\n    _download_to_tmp_and_move(\n  File \"C:\\Users\\OM\\AppData\\Roaming\\Python\\Python311\\site-packages\\huggingface_hub\\file_download.py\", line 1543, in _download_to_tmp_and_move\n    http_get(\n  File \"C:\\Users\\OM\\AppData\\Roaming\\Python\\Python311\\site-packages\\huggingface_hub\\file_download.py\", line 455, in http_get\n    temp_file.write(chunk)\nOSError: [Errno 28] No space left on device\n\nwhile loading with TFBertForSequenceClassification, an error is thrown:\nTraceback (most recent call last):\n  File \"C:\\Users\\OM\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\pipelines\\base.py\", line 289, in infer_framework_load_model\n    model = model_class.from_pretrained(model, **kwargs)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\OM\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\modeling_tf_utils.py\", line 2843, in from_pretrained\n    resolved_archive_file = cached_file(\n                            ^^^^^^^^^^^^\n  File \"C:\\Users\\OM\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\utils\\hub.py\", line 403, in cached_file\n    resolved_file = hf_hub_download(\n                    ^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\OM\\AppData\\Roaming\\Python\\Python311\\site-packages\\huggingface_hub\\utils\\_validators.py\", line 114, in _inner_fn\n    return fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\OM\\AppData\\Roaming\\Python\\Python311\\site-packages\\huggingface_hub\\file_download.py\", line 860, in hf_hub_download\n    return _hf_hub_download_to_cache_dir(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\OM\\AppData\\Roaming\\Python\\Python311\\site-packages\\huggingface_hub\\file_download.py\", line 1009, in _hf_hub_download_to_cache_dir\n    _download_to_tmp_and_move(\n  File \"C:\\Users\\OM\\AppData\\Roaming\\Python\\Python311\\site-packages\\huggingface_hub\\file_download.py\", line 1543, in _download_to_tmp_and_move\n    http_get(\n  File \"C:\\Users\\OM\\AppData\\Roaming\\Python\\Python311\\site-packages\\huggingface_hub\\file_download.py\", line 455, in http_get\n    temp_file.write(chunk)\nOSError: [Errno 28] No space left on device\n\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 85\u001b[0m\n\u001b[0;32m     82\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m     84\u001b[0m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[1;32m---> 85\u001b[0m scraper \u001b[38;5;241m=\u001b[39m \u001b[43mFinancialNewsScraper\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     86\u001b[0m articles \u001b[38;5;241m=\u001b[39m scraper\u001b[38;5;241m.\u001b[39mscrape_news(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mReliance\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2023-01-01\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2023-01-07\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     87\u001b[0m sentiment_results \u001b[38;5;241m=\u001b[39m scraper\u001b[38;5;241m.\u001b[39manalyze_sentiment(articles)\n",
      "Cell \u001b[1;32mIn[6], line 11\u001b[0m, in \u001b[0;36mFinancialNewsScraper.__init__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheaders \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUser-Agent\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      5\u001b[0m }\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msources \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreuters\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://www.reuters.com/markets/companies\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmarketwatch\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://www.marketwatch.com/markets\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minvesting\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://www.investing.com/news/stock-market-news\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     10\u001b[0m }\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msentiment_analyzer \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msentiment-analysis\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43myiyanghkust/finbert-tone\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\pipelines\\__init__.py:940\u001b[0m, in \u001b[0;36mpipeline\u001b[1;34m(task, model, config, tokenizer, feature_extractor, image_processor, processor, framework, revision, use_fast, token, device, device_map, torch_dtype, trust_remote_code, model_kwargs, pipeline_class, **kwargs)\u001b[0m\n\u001b[0;32m    938\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m framework \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    939\u001b[0m     model_classes \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m\"\u001b[39m: targeted_task[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m: targeted_task[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m]}\n\u001b[1;32m--> 940\u001b[0m     framework, model \u001b[38;5;241m=\u001b[39m \u001b[43minfer_framework_load_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    941\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    942\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_classes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    943\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    944\u001b[0m \u001b[43m        \u001b[49m\u001b[43mframework\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframework\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    945\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    946\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    947\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    948\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    950\u001b[0m model_config \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mconfig\n\u001b[0;32m    951\u001b[0m hub_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39m_commit_hash\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\pipelines\\base.py:302\u001b[0m, in \u001b[0;36minfer_framework_load_model\u001b[1;34m(model, config, model_classes, task, framework, **model_kwargs)\u001b[0m\n\u001b[0;32m    300\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m class_name, trace \u001b[38;5;129;01min\u001b[39;00m all_traceback\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m    301\u001b[0m             error \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhile loading with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclass_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, an error is thrown:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mtrace\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 302\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    303\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not load model \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with any of the following classes: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclass_tuple\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. See the original errors:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00merror\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    304\u001b[0m         )\n\u001b[0;32m    306\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m framework \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    307\u001b[0m     framework \u001b[38;5;241m=\u001b[39m infer_framework(model\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Could not load model yiyanghkust/finbert-tone with any of the following classes: (<class 'transformers.models.auto.modeling_auto.AutoModelForSequenceClassification'>, <class 'transformers.models.auto.modeling_tf_auto.TFAutoModelForSequenceClassification'>, <class 'transformers.models.bert.modeling_bert.BertForSequenceClassification'>, <class 'transformers.models.bert.modeling_tf_bert.TFBertForSequenceClassification'>). See the original errors:\n\nwhile loading with AutoModelForSequenceClassification, an error is thrown:\nTraceback (most recent call last):\n  File \"C:\\Users\\OM\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\pipelines\\base.py\", line 289, in infer_framework_load_model\n    model = model_class.from_pretrained(model, **kwargs)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\OM\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\models\\auto\\auto_factory.py\", line 564, in from_pretrained\n    return model_class.from_pretrained(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\OM\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\modeling_utils.py\", line 3805, in from_pretrained\n    resolved_archive_file = cached_file(\n                            ^^^^^^^^^^^^\n  File \"C:\\Users\\OM\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\utils\\hub.py\", line 403, in cached_file\n    resolved_file = hf_hub_download(\n                    ^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\OM\\AppData\\Roaming\\Python\\Python311\\site-packages\\huggingface_hub\\utils\\_validators.py\", line 114, in _inner_fn\n    return fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\OM\\AppData\\Roaming\\Python\\Python311\\site-packages\\huggingface_hub\\file_download.py\", line 860, in hf_hub_download\n    return _hf_hub_download_to_cache_dir(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\OM\\AppData\\Roaming\\Python\\Python311\\site-packages\\huggingface_hub\\file_download.py\", line 1009, in _hf_hub_download_to_cache_dir\n    _download_to_tmp_and_move(\n  File \"C:\\Users\\OM\\AppData\\Roaming\\Python\\Python311\\site-packages\\huggingface_hub\\file_download.py\", line 1543, in _download_to_tmp_and_move\n    http_get(\n  File \"C:\\Users\\OM\\AppData\\Roaming\\Python\\Python311\\site-packages\\huggingface_hub\\file_download.py\", line 455, in http_get\n    temp_file.write(chunk)\nOSError: [Errno 28] No space left on device\n\nwhile loading with TFAutoModelForSequenceClassification, an error is thrown:\nTraceback (most recent call last):\n  File \"C:\\Users\\OM\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\pipelines\\base.py\", line 289, in infer_framework_load_model\n    model = model_class.from_pretrained(model, **kwargs)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\OM\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\models\\auto\\auto_factory.py\", line 564, in from_pretrained\n    return model_class.from_pretrained(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\OM\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\modeling_tf_utils.py\", line 2843, in from_pretrained\n    resolved_archive_file = cached_file(\n                            ^^^^^^^^^^^^\n  File \"C:\\Users\\OM\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\utils\\hub.py\", line 403, in cached_file\n    resolved_file = hf_hub_download(\n                    ^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\OM\\AppData\\Roaming\\Python\\Python311\\site-packages\\huggingface_hub\\utils\\_validators.py\", line 114, in _inner_fn\n    return fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\OM\\AppData\\Roaming\\Python\\Python311\\site-packages\\huggingface_hub\\file_download.py\", line 860, in hf_hub_download\n    return _hf_hub_download_to_cache_dir(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\OM\\AppData\\Roaming\\Python\\Python311\\site-packages\\huggingface_hub\\file_download.py\", line 1009, in _hf_hub_download_to_cache_dir\n    _download_to_tmp_and_move(\n  File \"C:\\Users\\OM\\AppData\\Roaming\\Python\\Python311\\site-packages\\huggingface_hub\\file_download.py\", line 1543, in _download_to_tmp_and_move\n    http_get(\n  File \"C:\\Users\\OM\\AppData\\Roaming\\Python\\Python311\\site-packages\\huggingface_hub\\file_download.py\", line 455, in http_get\n    temp_file.write(chunk)\nOSError: [Errno 28] No space left on device\n\nwhile loading with BertForSequenceClassification, an error is thrown:\nTraceback (most recent call last):\n  File \"C:\\Users\\OM\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\pipelines\\base.py\", line 289, in infer_framework_load_model\n    model = model_class.from_pretrained(model, **kwargs)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\OM\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\modeling_utils.py\", line 3805, in from_pretrained\n    resolved_archive_file = cached_file(\n                            ^^^^^^^^^^^^\n  File \"C:\\Users\\OM\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\utils\\hub.py\", line 403, in cached_file\n    resolved_file = hf_hub_download(\n                    ^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\OM\\AppData\\Roaming\\Python\\Python311\\site-packages\\huggingface_hub\\utils\\_validators.py\", line 114, in _inner_fn\n    return fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\OM\\AppData\\Roaming\\Python\\Python311\\site-packages\\huggingface_hub\\file_download.py\", line 860, in hf_hub_download\n    return _hf_hub_download_to_cache_dir(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\OM\\AppData\\Roaming\\Python\\Python311\\site-packages\\huggingface_hub\\file_download.py\", line 1009, in _hf_hub_download_to_cache_dir\n    _download_to_tmp_and_move(\n  File \"C:\\Users\\OM\\AppData\\Roaming\\Python\\Python311\\site-packages\\huggingface_hub\\file_download.py\", line 1543, in _download_to_tmp_and_move\n    http_get(\n  File \"C:\\Users\\OM\\AppData\\Roaming\\Python\\Python311\\site-packages\\huggingface_hub\\file_download.py\", line 455, in http_get\n    temp_file.write(chunk)\nOSError: [Errno 28] No space left on device\n\nwhile loading with TFBertForSequenceClassification, an error is thrown:\nTraceback (most recent call last):\n  File \"C:\\Users\\OM\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\pipelines\\base.py\", line 289, in infer_framework_load_model\n    model = model_class.from_pretrained(model, **kwargs)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\OM\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\modeling_tf_utils.py\", line 2843, in from_pretrained\n    resolved_archive_file = cached_file(\n                            ^^^^^^^^^^^^\n  File \"C:\\Users\\OM\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\utils\\hub.py\", line 403, in cached_file\n    resolved_file = hf_hub_download(\n                    ^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\OM\\AppData\\Roaming\\Python\\Python311\\site-packages\\huggingface_hub\\utils\\_validators.py\", line 114, in _inner_fn\n    return fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\OM\\AppData\\Roaming\\Python\\Python311\\site-packages\\huggingface_hub\\file_download.py\", line 860, in hf_hub_download\n    return _hf_hub_download_to_cache_dir(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\OM\\AppData\\Roaming\\Python\\Python311\\site-packages\\huggingface_hub\\file_download.py\", line 1009, in _hf_hub_download_to_cache_dir\n    _download_to_tmp_and_move(\n  File \"C:\\Users\\OM\\AppData\\Roaming\\Python\\Python311\\site-packages\\huggingface_hub\\file_download.py\", line 1543, in _download_to_tmp_and_move\n    http_get(\n  File \"C:\\Users\\OM\\AppData\\Roaming\\Python\\Python311\\site-packages\\huggingface_hub\\file_download.py\", line 455, in http_get\n    temp_file.write(chunk)\nOSError: [Errno 28] No space left on device\n\n\n"
     ]
    }
   ],
   "source": [
    "class FinancialNewsScraper:\n",
    "    def __init__(self):\n",
    "        self.headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'\n",
    "        }\n",
    "        self.sources = {\n",
    "            'reuters': 'https://www.reuters.com/markets/companies',\n",
    "            'marketwatch': 'https://www.marketwatch.com/markets',\n",
    "            'investing': 'https://www.investing.com/news/stock-market-news'\n",
    "        }\n",
    "        self.sentiment_analyzer = pipeline(\"sentiment-analysis\", model=\"yiyanghkust/finbert-tone\")\n",
    "\n",
    "    def scrape_news(self, company: str, start_date: str, end_date: str) -> List[NewsArticle]:\n",
    "        articles = []\n",
    "        current_date = datetime.strptime(start_date, '%Y-%m-%d')\n",
    "        end_date = datetime.strptime(end_date, '%Y-%m-%d')\n",
    "        \n",
    "        while current_date <= end_date:\n",
    "            for source, url in self.sources.items():\n",
    "                try:\n",
    "                    articles.extend(self._scrape_source(source, url, company, current_date))\n",
    "                    time.sleep(2)  # Polite delay between sources\n",
    "                except Exception as e:\n",
    "                    logging.error(f\"Error scraping {source}: {str(e)}\")\n",
    "            current_date += timedelta(days=1)\n",
    "        return articles\n",
    "\n",
    "    def _scrape_source(self, source: str, url: str, company: str, date: datetime) -> List[NewsArticle]:\n",
    "        articles = []\n",
    "        try:\n",
    "            response = requests.get(url, headers=self.headers)\n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "            \n",
    "            if source == 'reuters':\n",
    "                articles.extend(self._parse_reuters(soup, company, date))\n",
    "            elif source == 'marketwatch':\n",
    "                articles.extend(self._parse_marketwatch(soup, company, date))\n",
    "            elif source == 'investing':\n",
    "                articles.extend(self._parse_investing(soup, company, date))\n",
    "                \n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error in _scrape_source for {source}: {str(e)}\")\n",
    "            \n",
    "        return articles\n",
    "\n",
    "    def _parse_reuters(self, soup: BeautifulSoup, company: str, date: datetime) -> List[NewsArticle]:\n",
    "        articles = []\n",
    "        for article in soup.find_all('article'):\n",
    "            try:\n",
    "                title = article.find('h3').text.strip()\n",
    "                if company.lower() in title.lower():\n",
    "                    link = article.find('a')['href']\n",
    "                    article_content = self._get_article_content(f\"https://reuters.com{link}\")\n",
    "                    articles.append(NewsArticle(title, article_content, date.strftime('%Y-%m-%d'), 'Reuters', link))\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Error parsing Reuters article: {str(e)}\")\n",
    "        return articles\n",
    "\n",
    "    def _get_article_content(self, url: str) -> str:\n",
    "        try:\n",
    "            response = requests.get(url, headers=self.headers)\n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "            paragraphs = soup.find_all('p')\n",
    "            return ' '.join([p.text.strip() for p in paragraphs])\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error getting article content: {str(e)}\")\n",
    "            return \"\"\n",
    "\n",
    "    def analyze_sentiment(self, articles: List[NewsArticle]) -> List[dict]:\n",
    "        results = []\n",
    "        for article in articles:\n",
    "            sentiment = self.sentiment_analyzer(article.content)\n",
    "            results.append({\n",
    "                'title': article.title,\n",
    "                'content': article.content,\n",
    "                'date': article.date,\n",
    "                'source': article.source,\n",
    "                'url': article.url,\n",
    "                'sentiment': sentiment[0]['label'],\n",
    "                'score': sentiment[0]['score']\n",
    "            })\n",
    "        return results\n",
    "\n",
    "# Example usage\n",
    "scraper = FinancialNewsScraper()\n",
    "articles = scraper.scrape_news('Reliance', '2023-01-01', '2023-01-07')\n",
    "sentiment_results = scraper.analyze_sentiment(articles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
